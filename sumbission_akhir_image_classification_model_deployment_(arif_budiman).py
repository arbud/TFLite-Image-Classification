# -*- coding: utf-8 -*-
"""Sumbission Akhir : Image Classification Model Deployment (Arif Budiman).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15mW72zxmGXcEyJL_pfrkPWFfp8waxMmi

# **Proyek Akhir : Image Classification Model Deployment - Bottle Synthetic**
### Nama : Arif Budiman
### E-mail : arifbudiman2506@gmail.com
### ID Dicoding : arbud25

# **Pendahuluan**

Pertama-tama dalam proyek ini saya menggunakan dataset yang diperoleh dari [kaggle](https://www.kaggle.com/) yaitu data [Bottles Synthetic Images](https://www.kaggle.com/datasets/vencerlanz09/bottle-synthetic-images-dataset).

Data dari link kaggel tersebut akan dicopy API nya untuk diambil datanya berikut API dari Bottles Synthetic Images : (kaggle datasets download -d vencerlanz09/bottle-synthetic-images-dataset).

Berikut API Token yang diperoleh dari kaggle : [Kaggle API Token](https://drive.google.com/file/d/1OnxF8SKCfAsk5b2iBSU2v3NoIvWdwZjZ/view?pli=1).

Tujuan proyek ini adalah untuk membuat model kalsifikasi dari dataset botol yang nanti akan diklasifikasikan menjadi berbagai macam kategori, lalu model yang telah dibuat akan di convert dengan menggunakan TFLite

# **Import Library**
"""

!pip install split-folders
import pandas as pd
import numpy as np
import os
import tensorflow as tf
import splitfolders
import time
import pathlib
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

"""# **Import Data Dari Kaggle Dengan API Command**"""

# Install kaggle API
!pip install kaggle

# Upload API Kaggle yang telah diperoleh
from google.colab import files

uploaded = files.upload()

# Set Up Directory Untuk Kaggle pada Google dan Download Datasetnya
import os

# Set up Kaggle directory
!mkdir ~/.kaggle

# Move the Kaggle API key to the correct location
!mv kaggle.json ~/.kaggle/

# Set permissions for the API key
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset using Kaggle API
!kaggle datasets download -d vencerlanz09/bottle-synthetic-images-dataset

# Unzip the downloaded dataset
!unzip -q bottle-synthetic-images-dataset.zip -d dataset

# Cek isi pada direktori
os.listdir('/content/dataset/Bottle Images/Bottle Images')

# Cek jumlah datanya
def count_files_in_folder(folder_path):
    total_files = 0

    for root, dirs, files in os.walk(folder_path):
        total_files += len(files)

    return total_files

main_folder_path = '/content/dataset/Bottle Images/Bottle Images'

total_files_count = count_files_in_folder(main_folder_path)

print(f"Total jumlah data yang terdapat pada folder dan subfolders: {total_files_count}")

"""# **Train Test Split Data**

Untuk pembagian datanya adalah validation set 20% dari total dataset, pembagian data menggunakan library split-folders
"""

# Buat Direktori Baru Untuk Ujicoba
# Tentukan path lengkap untuk direktori baru
new_directory = '/content/bottle_synthetic'

# Periksa apakah direktori sudah ada atau belum
if not os.path.exists(new_directory):
    # Jika belum, buat direktori baru
    os.makedirs(new_directory)
    print(f"Direktori {new_directory} berhasil dibuat.")
else:
    print(f"Direktori {new_directory} sudah ada.")

# Gunakan split-folders untuk membagi dataset dan pindahkan ke folder yang baru dibuat dengan rasio train 80% dan val 20%
# Path sumber dataset
source_dir = '/content/dataset/Bottle Images/Bottle Images'

# Path direktori tujuan untuk data pelatihan dan validasi
output_dir = '/content/bottle_synthetic'

# Gunakan splitfolders untuk membagi dataset
splitfolders.ratio(source_dir, output=output_dir, seed=42, ratio=(0.8, 0.2))

print("Data berhasil dibagi antara data latih dan data validasi.")

# Cek data latih pada folder baru
train_dir = '/content/bottle_synthetic/train'
os.listdir(train_dir)

# Cek data validasi pada folder baru
val_dir = '/content/bottle_synthetic/val'
os.listdir(val_dir)

"""# **Preprocessing Data**"""

# Menggunakan augmentasi gambar menggunakan ImageDataGenerator
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True,
    fill_mode='nearest'
    )

train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=128,
                                                    class_mode='categorical',
                                                    target_size=(150, 150))

validation_datagen = ImageDataGenerator(
    rescale=1.0/255
)

validation_generator = validation_datagen.flow_from_directory(val_dir,
                                                              batch_size=32,
                                                              class_mode='categorical',
                                                              target_size=(150, 150))

"""# **Membuat Model**"""

# Buat arsitektur model dengan sequential
model_bottle = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64,(3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(128,(3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(256,(3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(5, activation='softmax')
])

# Melihat summary model
model_bottle.summary()

# Compile model yang sudah dibuat dengan learning_rate 1e-4 dan epochs 50
learning_rate = 1e-4
nomor_epochs = 50

optimizer = tf.optimizers.Adam(lr=learning_rate)
model_bottle.compile(optimizer=optimizer,
                     loss='categorical_crossentropy',
                     metrics=['accuracy'])

# Buat fungsi callback untuk mengetahui apabila akurasi dan val_akurasi sudah mencapai nilai yang diinginkan (92)
class MyCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if logs.get('accuracy') > 0.92 and logs.get('val_accuracy') > 0.92:
            print("\nAkurasi dan val_accuracy telah mencapai >92%!")
            self.model.stop_training = True

callbacks = MyCallback()

start = time.time()
history_bottle = model_bottle.fit(train_generator,
                                  epochs=nomor_epochs,
                                  steps_per_epoch=50,
                                  validation_data=validation_generator,
                                  batch_size=128,
                                  verbose=2,
                                  callbacks=[callbacks])
stop = time.time()
print(f"Lama Waktu Training yang Dibutuhkan: {round((stop - start)/60)}minute")

# Buat grafik untuk mengetahui akurasi dan loss
acc = history_bottle.history['accuracy']
val_acc = history_bottle.history['val_accuracy']

loss = history_bottle.history['loss']
val_loss = history_bottle.history['val_loss']

plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()),1])
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Categorical CrossEntropy')
plt.ylim([0,1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()

"""# **Convert Model**

Convert model yang telah dibuat dan diuji dengan Format TFLite
"""

export_dir = 'saved_model/'
tf.saved_model.save(model_bottle, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('bottle.tflite')
tflite_model_file.write_bytes(tflite_model)